{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37af7ffa",
   "metadata": {},
   "source": [
    "# Image Captioning project\n",
    "Build our first prototype model for Image captioning using structure combination of CNN and Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f916c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_1 = 'Qinghuan Liu'\n",
    "name_2 = 'Jingkai Zhou'\n",
    "name_3 = 'Chang Li'\n",
    "naem_4 = 'Yawen Liu'\n",
    "planning_group = '28'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a7210",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Import\n",
    "import possible files here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf5757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca572b3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load dataset\n",
    "In this part, load and preprocess famous captioning dataset ['Flickr 8k Dataset'](https://www.kaggle.com/datasets/adityajn105/flickr8k). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02912247",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.1 Load dataset from disk and split into training / validation / test sets\n",
    "Since the size of our trainning archive is not relatively large, the ratio is chosen according to the technique [Data splitting technique to fit any Machine Learning Model](https://towardsdatascience.com/data-splitting-technique-to-fit-any-machine-learning-model-c0d7f3f1c790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65e45686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Some file system operation are not covered by 'Path' and we use 'shutil' for that\n",
    "import shutil\n",
    "\n",
    "# Regular expressions are used to find patterns in strings\n",
    "import re\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e5f91",
   "metadata": {},
   "source": [
    "Statistical information on dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddc13be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8091\n",
      "G:\\GitHub\\Deep_Learning_Proj\\archive\\Images\\1000268201_693b08cb0e.jpg\n"
     ]
    }
   ],
   "source": [
    "# Path to Flickr8K_ photos\n",
    "path_Flickr_jpg = \"G:/GitHub/Deep_Learning_Proj/archive/Images\"\n",
    "# Path to caption file\n",
    "path_Flickr_text = \"G:/GitHub/Deep_Learning_Proj/archive/captions.txt\"\n",
    "\n",
    "image_all = Path.cwd() / \"G:/GitHub/Deep_Learning_Proj/archive/Images/\"\n",
    "\n",
    "all_image_filenames = list(image_all.glob(\"*.jpg\"))\n",
    "\n",
    "print(len(all_image_filenames))\n",
    "print(all_image_filenames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc3b32",
   "metadata": {},
   "source": [
    "split data with predefined ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35fae265",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio_dataset = 0.2\n",
    "\n",
    "image_train, image_val = \\\n",
    "train_test_split(all_image_filenames,  \n",
    "              test_size = split_ratio_dataset,\n",
    "              random_state = 2)\n",
    "\n",
    "# Following operations create train and val dataset folders located at the same root as this proj.ipynb\n",
    "subdirectories = {\"./image_train\": image_train,\n",
    "                 \"./image_val\": image_val\n",
    "                 }\n",
    "\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory = Path(subdirectory)\n",
    "    subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    \n",
    "# Put the training and validation data in the respective folders\n",
    "def fill_sub_dir(sub_dir, file_subset):\n",
    "    \"\"\"This function copies files from the `train_all` to a `<sub_dir>`\n",
    "    A more efficient solution would be to use \"symbolic links\" (see https://kb.iu.edu/d/abbe)\n",
    "    but for simplicity hard copies is used instead.\n",
    "    \"\"\"\n",
    "    for file in file_subset:\n",
    "        file_path = Path.cwd() / sub_dir / file.name\n",
    "        shutil.copyfile(file, file_path)\n",
    "        \n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aed8fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6472\n",
      "1619\n"
     ]
    }
   ],
   "source": [
    "print(len(image_train))\n",
    "print(len(image_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde7b8c",
   "metadata": {},
   "source": [
    "Point to training and validation path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79936e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./image_train/\"\n",
    "val_path = \"./image_val/\"\n",
    "caption_path = \"./captions.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecc980",
   "metadata": {},
   "source": [
    "Create a dictionary to store image names and its corresponding five captions {Key:Value} = {'img_name': \\['cap1', 'cap2', 'cap3', 'cap4', 'cap5' \\]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "130091d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('captions.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines.pop(0) # remove first desciption line in lines\n",
    "    \n",
    "dict_img_caps =  {}\n",
    "for i in range(int(len(lines)/5)):\n",
    "    txt_0 = lines[5*i+0].split(\",\")\n",
    "    txt_1 = lines[5*i+1].split(\",\")\n",
    "    txt_2 = lines[5*i+2].split(\",\")\n",
    "    txt_3 = lines[5*i+3].split(\",\")\n",
    "    txt_4 = lines[5*i+4].split(\",\")\n",
    "    \n",
    "    img_name = txt_0[0] # get img file name\n",
    "    txt_cap = [txt_0[1], txt_1[1], txt_2[1], txt_3[1], txt_4[1]] # list of five captions per img\n",
    "    \n",
    "    dict_img_caps[img_name] = txt_cap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8d5e7",
   "metadata": {},
   "source": [
    "## 1.2 Create image class\n",
    "Here, as what we did before in HA1, new class img_cap is created with some neccessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9da4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from itertools import chain\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "class img_cap(Dataset):\n",
    "    \n",
    "    def __init__(self, root, transform):\n",
    "        \"\"\"Constructor\n",
    "        \n",
    "        Args:\n",
    "            root (Path/str): Filepath to the data root, e.g. './small_train'\n",
    "            transform (Compose): A composition of image transforms, see below.\n",
    "        \"\"\"\n",
    "        \n",
    "        root = Path(root)\n",
    "        if not (root.exists() and root.is_dir()):\n",
    "            raise ValueError(f\"Data root '{root}' is invalid\")\n",
    "            \n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self._dog_label = dog_label\n",
    "        self._cat_label = cat_label\n",
    "        \n",
    "        # Collect samples, both cat and dog and store pairs of (filepath, label) in a simple list.\n",
    "        self._samples = self._collect_samples()\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get sample by index\n",
    "        \n",
    "        Args:\n",
    "            index (int)\n",
    "        \n",
    "        Returns:\n",
    "             The index'th sample (Tensor, int)\n",
    "        \"\"\"\n",
    "        # Access the stored path and label for the correct index\n",
    "        path, label = self._samples[index]\n",
    "        # Load the image into memory\n",
    "        img = Image.open(path)\n",
    "        # Perform transforms, if any.\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Total number of samples\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return len(self._samples)\n",
    "    \n",
    "    def _collect_samples(self):\n",
    "        \"\"\"Collect all paths and labels\n",
    "        \n",
    "        Helper method for the constructor\n",
    "        \"\"\"\n",
    "        # Iterator over dog filpath\n",
    "        dog_paths = self._collect_imgs_sub_dir(self.root / \"dogs\")\n",
    "        # Iterator of pairs (path, dog label)\n",
    "        # Again, we use the `map` function to create an iterator. It's use is not as common as the so called\n",
    "        # 'list comprehension' you've previously seen, but a good alternative to have seen.\n",
    "        dog_paths_and_labels = map(lambda path: (path, self._dog_label), dog_paths)\n",
    "        # Same for cats\n",
    "        cat_paths = self._collect_imgs_sub_dir(self.root / \"cats\")\n",
    "        cat_paths_and_labels = map(lambda path: (path, self._cat_label), cat_paths)\n",
    "        # Sorting is not strictly necessary, but filesystem globbing (wildcard search) is not deterministic,\n",
    "        # and consistency is nice when debugging.\n",
    "        return sorted(list(chain(dog_paths_and_labels, cat_paths_and_labels)), key=lambda x: x[0].stem)\n",
    "     \n",
    "    @staticmethod\n",
    "    def _collect_imgs_sub_dir(sub_dir: Path):\n",
    "        \"\"\"Collect image paths in a directory\n",
    "        \n",
    "        Helper method for the constructor\n",
    "        \"\"\"\n",
    "        if not sub_dir.exists():\n",
    "            raise ValueError(f\"Data root '{self.root}' must contain sub dir '{sub_dir.name}'\")\n",
    "        return sub_dir.glob(\"*.jpg\")\n",
    "    \n",
    "    def get_sample_by_id(self, id_):\n",
    "        \"\"\"Get sample by image id\n",
    "        \n",
    "        Convenience method for exploration.\n",
    "        The indices does not correspond to the image id's in the filenames.\n",
    "        Here is a (rather inefficient) way of inspecting a specific image.\n",
    "        \n",
    "        Args:\n",
    "            id_ (str): Image id, e.g. `dog.321`\n",
    "        \"\"\"\n",
    "        id_index = [path.stem for (path, _) in self._samples].index(id_)\n",
    "        return self[id_index]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
